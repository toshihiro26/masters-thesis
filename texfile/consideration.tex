\section{考察}\label{consideration}

\subsection{ログの分析結果がそのようになった理由の検討}\label{consideration_checklog}
1,2,3のように主訴が記載されている対話ログのみならず，主訴の単語が記載されておらず関連した内容が記載された対話ログやその病気によって引き起こされる症状などが記載されている対話ログについても，動作の判別結果の対象することができた．
\par
これはLLMによって学習されているデータの中に主訴に関連している情報の中に特定の症状が含まれることで，主訴に関連して動作すべきと判断することができたからだと考えられる．
一方で，人手でのタグ付けの際に動作すべきでないと判断した対話ログにも判別結果として動作すべきとして出力されたものも多く存在した．
このようなことが起こった原因として，模擬患者の主訴に関する情報を医師に伝えるための動作として，主訴に関する内容の出現を動作の判定基準にしていたため，主訴の説明とは離れた「一日に吸うたばこの本数」などの情報が，主訴に関する情報としてとらえられてしまったため、動作の判別対象に選択されたのだと考えられる．
\par
これらの解決策として，主訴に関する情報のとらえ方を変える必要がある．現状のプロンプトでは主訴に関するすべての情報を捉えるように指示しているが，その情報が主訴の情報なのか，主訴に関連している情報なのかを分けて考える必要がある．今後の課題として，これらの要素を考慮したうえでの入力プロンプトにおける判断基準の調整をしていく必要がある．

\subsection{患者動作の生成物の更なる改善点について}\label{consideration_generate}
図XXから図ZZより，シナリオに記載されている情報からエージェントの患者動作を生成することができた．
これにより，医療面接シミュレータにおけるより自然な対話の実現を行うことができると考えられる．ただし，生成された患者動作においてはいくつか課題が残った．1つ目がエージェント画像の再現度，二つ目が動作の不自然さである．生成された患者動作動画は，顔の部分が歪み，また患者動作を取らせることによるモーションの変化に対応しきれていない．
\par
この理由として，今回の研究で使用したMagicanimateの仕様が挙げられる．Magicanimateでは元画像とモーションビデオにおけるそれぞれの人物の位置関係が完全に一致していなければ，生成後の姿が一部崩れたことになる．また細かい部分の表現はまだ難しく，手などの部分が一つの塊としてとらえられることで本来の形から離れていったのではないかと考えられる．
そのため，今後の課題としてDeepfakeなどを用いた動画に対する顔の修正や体の部位の復元が挙げられる．

\section{システム全体についての検討と改善点}\label{consideration_system}
subsection{エージェント画像}
４．２．２節で用いたエージェント画像生成について，エージェント画像をシナリオから生成することで事前にシナリオに合った画像を用意する必要がなくなる．ただし，生成された画像についてはDALLE3で生成される画像は他の画像生成AIと比較してかなり優れているが，医療面接において最適な画像であるとは限らない．そのため，生成した画像を確認するユーザとは異なる第三者が必要となる．
よって，システムの運用において，独立的にエージェント画像の生成から患者動作動画生成まで一律して行うために，そのロールプレイングの場面におけるエージェント画像の自動評価を行うことが今後の課題である．

\subsection{モーションビデオ}
今回の研究では，モーションビデオは医療面接における患者動作として想定される７つの患者動作を選択し，撮影を行い，モーションビデオであるDenseposeに変換した．患者動作を追加する際には，作成したい患者動作の動きを撮影することで新たなモーションビデオとして追加するができる．一方で追加されたモーションを判別する際には，人手でモーションに関する識別タグを用意し，判別用に入力しなければならない．
\par
そのため，今後のシミュレータとして活用していく際に，モーションビデオに対して自動的に識別タグを用意し，判別用に入力できるようにすることでより柔軟にモーションビデオの変化に対応できることが望ましい．
